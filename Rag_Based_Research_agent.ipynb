{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8872945-eb79-4a0e-b1dc-68b2c3b1a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.parse\n",
    "from ddgs import DDGS          # package name is 'ddgs' (duckduckgo_search renamed)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf3ecb1-3195-4dc8-aa29-819fa72629d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ddgs in c:\\users\\vivek\\anaconda3\\lib\\site-packages (9.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vivek\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\vivek\\anaconda3\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\vivek\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from ddgs) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.15.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from ddgs) (0.15.0)\n",
      "Requirement already satisfied: lxml>=4.9.4 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from ddgs) (5.3.0)\n",
      "Requirement already satisfied: httpx>=0.28.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Requirement already satisfied: fake-useragent>=2.2.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from ddgs) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from click>=8.1.8->ddgs) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Requirement already satisfied: brotli in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
      "Requirement already satisfied: socksio==1.* in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vivek\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ddgs requests beautifulsoup4 sentence-transformers numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec619a6-1ef0-46cc-a9d2-85a534ca98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.parse\n",
    "from ddgs import DDGS          # package name is 'ddgs' (duckduckgo_search renamed)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c547a7-1784-4145-905e-b40173fbe5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_RESULTS = 6        # How many URLs to check\n",
    "PASSAGES_PER_PAGE = 4     # How many passages to pull from each URL\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\" # Fast, high-quality model\n",
    "TOP_PASSAGES = 5          # How many relevant passages to use for the summary\n",
    "SUMMARY_SENTENCES = 3     # How many sentences in the final summary\n",
    "TIMEOUT = 8               # How long to wait for a webpage to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc937a2a-c149-4c2a-9432-0d2bb8093b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_ddg(url):\n",
    "    \"\"\"If DuckDuckGo returns a redirect wrapper, extract the real URL.\"\"\"\n",
    "    try:\n",
    "        parsed = urllib.parse.urlparse(url)\n",
    "        if \"duckduckgo.com\" in parsed.netloc:\n",
    "            qs = urllib.parse.parse_qs(parsed.query)\n",
    "            uddg = qs.get(\"uddg\")\n",
    "            if uddg:\n",
    "                return urllib.parse.unquote(uddg[0])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return url\n",
    "\n",
    "def search_web(query, max_results=SEARCH_RESULTS):\n",
    "    \"\"\"Search the web and return a list of URLs.\"\"\"\n",
    "    urls = []\n",
    "    with DDGS() as ddgs:\n",
    "        for r in ddgs.text(query, max_results=max_results):\n",
    "            url = r.get(\"href\") or r.get(\"url\")\n",
    "            if not url:\n",
    "                continue\n",
    "            url = unwrap_ddg(url) # Clean up DDG redirect links\n",
    "            urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b5f132-85da-445d-923b-5427615a3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_text(url, timeout=TIMEOUT):\n",
    "    \"\"\"Fetch and clean text content from a URL.\"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (research-agent)\"}\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout, headers=headers, allow_redirects=True)\n",
    "        if r.status_code != 200:\n",
    "            return \"\"\n",
    "        \n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        # Remove noisy tags\n",
    "        for tag in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"svg\", \"iframe\", \"nav\", \"aside\"]):\n",
    "            tag.extract()\n",
    "\n",
    "        # Try paragraphs first\n",
    "        paragraphs = [p.get_text(\" \", strip=True) for p in soup.find_all(\"p\")]\n",
    "        text = \" \".join([p for p in paragraphs if p])\n",
    "\n",
    "        # If empty, fall back to divs with a lot of text\n",
    "        if not text.strip():\n",
    "            divs = [d.get_text(\" \", strip=True) for d in soup.find_all(\"div\")]\n",
    "            div_texts = [d for d in divs if len(d.split()) > 20]  # skip tiny divs\n",
    "            text = \" \".join(div_texts)\n",
    "\n",
    "        # If still empty, try meta description or title\n",
    "        if not text.strip():\n",
    "            meta = soup.find(\"meta\", attrs={\"name\": \"description\"}) or soup.find(\"meta\", attrs={\"property\": \"og:description\"})\n",
    "            if meta and meta.get(\"content\"):\n",
    "                text = meta[\"content\"].strip()\n",
    "            elif soup.title and soup.title.string:\n",
    "                text = soup.title.string.strip()\n",
    "\n",
    "        return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch {url}: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60445f4c-9334-4f60-b74b-199ef2807206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_passages(text, max_words=120):\n",
    "    \"\"\"Split long text into smaller passages.\"\"\"\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = words[i : i + max_words]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        i += max_words\n",
    "    return chunks\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"A simple sentence splitter.\"\"\"\n",
    "    parts = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "class ShortResearchAgent:\n",
    "    def __init__(self, embed_model=EMBEDDING_MODEL):\n",
    "        print(f\"Loading embedder: {embed_model}...\")\n",
    "        self.embedder = SentenceTransformer(embed_model)\n",
    "\n",
    "    def run(self, query):\n",
    "        start = time.time()\n",
    "        out = {\n",
    "            \"query\": query,\n",
    "            \"passages\": [],\n",
    "            \"summary\": \"\",\n",
    "            \"time\": 0.0\n",
    "        }\n",
    "\n",
    "        # --- 1. Search ---\n",
    "        urls = search_web(query)\n",
    "        print(f\"Found {len(urls)} urls.\")\n",
    "\n",
    "        # --- 2. Fetch & Chunk ---\n",
    "        docs = []\n",
    "        for u in urls:\n",
    "            txt = fetch_text(u)\n",
    "            if not txt:\n",
    "                print(f\"No text fetched from {u}\")\n",
    "                continue\n",
    "            chunks = chunk_passages(txt, max_words=120)\n",
    "            for c in chunks[:PASSAGES_PER_PAGE]:\n",
    "                docs.append({\"url\": u, \"passage\": c})\n",
    "\n",
    "        if not docs:\n",
    "            print(\"No documents could be fetched. Returning empty result.\")\n",
    "            out[\"time\"] = time.time() - start\n",
    "            return out\n",
    "\n",
    "        # --- 3. Embed passages ---\n",
    "        texts = [d[\"passage\"] for d in docs]\n",
    "        emb_texts = self.embedder.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "        q_emb = self.embedder.encode([query], convert_to_numpy=True)[0]\n",
    "\n",
    "        # --- 4. Rank passages ---\n",
    "        def cosine(a, b):\n",
    "            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "        sims = [cosine(e, q_emb) for e in emb_texts]\n",
    "        top_idx = np.argsort(sims)[::-1][:TOP_PASSAGES]\n",
    "        top_passages = [{\"url\": docs[i][\"url\"], \"passage\": docs[i][\"passage\"], \"score\": float(sims[i])} for i in top_idx]\n",
    "        out[\"passages\"] = top_passages\n",
    "\n",
    "        # --- 5. Extractive Summary ---\n",
    "        sentences = []\n",
    "        for tp in top_passages:\n",
    "            for s in split_sentences(tp[\"passage\"]):\n",
    "                sentences.append({\"sent\": s, \"url\": tp[\"url\"]})\n",
    "\n",
    "        if sentences:\n",
    "            sent_texts = [s[\"sent\"] for s in sentences]\n",
    "            sent_embs = self.embedder.encode(sent_texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "            sent_sims = [cosine(e, q_emb) for e in sent_embs]\n",
    "\n",
    "            top_sent_idx = np.argsort(sent_sims)[::-1][:SUMMARY_SENTENCES]\n",
    "            chosen = [sentences[idx] for idx in top_sent_idx]\n",
    "\n",
    "            # De-duplicate\n",
    "            seen = set()\n",
    "            lines = []\n",
    "            for s in chosen:\n",
    "                key = s[\"sent\"].lower()[:80]\n",
    "                if key in seen:\n",
    "                    continue\n",
    "                seen.add(key)\n",
    "                lines.append(f\"{s['sent']} (Source: {s['url']})\")\n",
    "            out[\"summary\"] = \" \".join(lines)\n",
    "        else:\n",
    "            out[\"summary\"] = \"No summary could be generated.\"\n",
    "\n",
    "        out[\"time\"] = time.time() - start\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58634e37-a83a-425f-8972-647b28e2e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedder: sentence-transformers/all-MiniLM-L6-v2...\n",
      "Running query: What are the new rules on H1B?\n",
      "\n",
      "Found 6 urls.\n",
      "DEBUG OUT: {'query': 'What are the new rules on H1B?', 'passages': [{'url': 'https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process', 'passage': 'selection process to select unique beneficiaries based on properly submitted electronic registrations. If we select the unique beneficiary, then each registrant that registered for that beneficiary receives a registration selection notice and may file an H-1B cap-subject petition on their behalf. Selections take place after the initial registration period closes, so you do not need to register on the day the initial registration period opens. You can only file an H-1B cap-subject petition if you receive a selection notice for the beneficiary of the petition. FY 2026 H-1B Cap Process Update We selected enough unique beneficiaries during the initial registration period projected as needed to reach the fiscal year 2026 H-1B numerical allocations (H-1B cap), including the advanced degree exemption,', 'score': 0.5282158851623535}, {'url': 'https://www.cntravellerme.com/story/h1b-visa-rules', 'passage': \"A sudden change to US visa rules has sparked confusion among travellers and thrown one of the world's most competitive work permits into the spotlight. On 19 September 2025, a proclamation by President Donald Trump introduced a $100,000 fee for every new H-1B petition filed after 21 September, dramatically raising the cost of sponsorship for companies that rely on the programme to bring in overseas talent. The announcement sent shockwaves through global firms and workers alike, sparking immediate questions about who is affected, how it will be enforced, and what it means for international travel . Within 24 hours, officials clarified that existing H-1B holders and routine renewals are exempt, but the mixed signals in the first hours after the\", 'score': 0.4648791551589966}, {'url': 'https://www.cntravellerme.com/story/h1b-visa-rules', 'passage': 'new rule that slaps a $100,000 fee on every new H-1B petition filed after 21 September 2025. Two big changes happened this year. In January 2025, the US Citizenship and Immigration Services (USCIS) rolled out a “modernisation” of the system, which tightened the definition of which occupations can apply, expanded site visits to ensure workers are actually doing the jobs they were sponsored for, and cracked down on outsourcing firms. Then, in September 2025, came a major announcement: any new H-1B petition must be accompanied by a $100,000 payment. That makes what was already one of the world’s most competitive visas significantly harder to access, and means sponsorship decisions now carry serious financial implications, especially for firms that previously hired', 'score': 0.4606855809688568}, {'url': 'https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process', 'passage': 'also known as the master’s cap. We selected 118,660 unique beneficiaries, resulting in 120,141 selected registrations in the initial selection for the FY 2026 H-1B cap. We have now received enough petitions to reach the congressionally mandated 65,000 H-1B visa regular cap and the 20,000 H-1B visa U.S. advanced degree exemption, known as the master’s cap, for fiscal year 2026. FY 2026 H-1B Cap Registration Analysis During the registration period for the FY 2026 H-1B cap, we saw a significant decrease in the total number of registrations submitted and eligible beneficiaries compared to FY 2025, including a decrease in the number of registrations submitted on behalf of beneficiaries with multiple registrations. Historical Data This chart shows registration and selection numbers', 'score': 0.44165661931037903}, {'url': 'https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process', 'passage': 'cap, you and your authorized representative, if applicable, must complete an electronic registration that requires basic information about you and each unique beneficiary you are requesting. We require registrants to provide valid passport information or valid travel document information for each beneficiary. The passport or travel document provided must be the one the beneficiary intends to use to enter the United States if they are issued an H-1B visa. Each beneficiary must only be registered under one passport or travel document. For additional information on the passport or valid travel document requirement, please see the Frequently Asked Questions section below. The initial registration period is for a minimum of 14 calendar days each fiscal year. USCIS then runs the H-1B', 'score': 0.43811938166618347}], 'summary': 'Within 24 hours, officials clarified that existing H-1B holders and routine renewals are exempt, but the mixed signals in the first hours after the (Source: https://www.cntravellerme.com/story/h1b-visa-rules) new rule that slaps a $100,000 fee on every new H-1B petition filed after 21 September 2025. (Source: https://www.cntravellerme.com/story/h1b-visa-rules) FY 2026 H-1B Cap Process Update We selected enough unique beneficiaries during the initial registration period projected as needed to reach the fiscal year 2026 H-1B numerical allocations (H-1B cap), including the advanced degree exemption, (Source: https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process)', 'time': 10.68739938735962}\n",
      "TYPE: <class 'dict'>\n",
      "\n",
      "Top passages:\n",
      "- score 0.528 src https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process\n",
      "  selection process to select unique beneficiaries based on properly submitted electronic registrations. If we select the unique beneficiary, then each registrant that registered for that beneficiary re...\n",
      "\n",
      "- score 0.465 src https://www.cntravellerme.com/story/h1b-visa-rules\n",
      "  A sudden change to US visa rules has sparked confusion among travellers and thrown one of the world's most competitive work permits into the spotlight. On 19 September 2025, a proclamation by Presiden...\n",
      "\n",
      "- score 0.461 src https://www.cntravellerme.com/story/h1b-visa-rules\n",
      "  new rule that slaps a $100,000 fee on every new H-1B petition filed after 21 September 2025. Two big changes happened this year. In January 2025, the US Citizenship and Immigration Services (USCIS) ro...\n",
      "\n",
      "- score 0.442 src https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process\n",
      "  also known as the master’s cap. We selected 118,660 unique beneficiaries, resulting in 120,141 selected registrations in the initial selection for the FY 2026 H-1B cap. We have now received enough pet...\n",
      "\n",
      "- score 0.438 src https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process\n",
      "  cap, you and your authorized representative, if applicable, must complete an electronic registration that requires basic information about you and each unique beneficiary you are requesting. We requir...\n",
      "\n",
      "--- Extractive summary ---\n",
      "Within 24 hours, officials clarified that existing H-1B holders and routine renewals are exempt, but the mixed signals in the first hours after the (Source: https://www.cntravellerme.com/story/h1b-visa-rules) new rule that slaps a $100,000 fee on every new H-1B petition filed after 21 September 2025. (Source: https://www.cntravellerme.com/story/h1b-visa-rules) FY 2026 H-1B Cap Process Update We selected enough unique beneficiaries during the initial registration period projected as needed to reach the fiscal year 2026 H-1B numerical allocations (H-1B cap), including the advanced degree exemption, (Source: https://www.uscis.gov/working-in-the-united-states/temporary-workers/h-1b-specialty-occupations/h-1b-electronic-registration-process)\n",
      "--------------------------\n",
      "\n",
      "Done in 10.7s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    agent = ShortResearchAgent()\n",
    "    q = \"What are the new rules on H1B?\"\n",
    "    \n",
    "    print(f\"Running query: {q}\\n\")\n",
    "    out = agent.run(q)\n",
    "\n",
    "    # ---- Debugging ----\n",
    "    print(\"DEBUG OUT:\", out)\n",
    "    print(\"TYPE:\", type(out))\n",
    "    # -------------------\n",
    "\n",
    "    if not out:\n",
    "        print(\"\\nAgent returned None. No results.\")\n",
    "    elif isinstance(out, dict) and \"passages\" in out:\n",
    "        print(\"\\nTop passages:\")\n",
    "        for p in out[\"passages\"]:\n",
    "            print(f\"- score {p['score']:.3f} src {p['url']}\\n  {p['passage'][:200]}...\\n\")\n",
    "\n",
    "        print(\"--- Extractive summary ---\")\n",
    "        print(out.get(\"summary\", \"No summary returned.\"))\n",
    "        print(\"--------------------------\")\n",
    "        print(f\"\\nDone in {out.get('time', -1):.1f}s\")\n",
    "    else:\n",
    "        print(\"\\nUnexpected agent output format:\")\n",
    "        print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e02ae-f90d-428f-bce0-695ad7abd319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
